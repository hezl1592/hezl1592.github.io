<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="zilch"><title>深度学习 | Strip Pooling · zilch个人博客</title><meta name="description" content="论文名称：Strip Pooling: Rethinking Spatial Pooling for Scene Parsing
论文链接：https://arxiv.org/abs/2003.13328
GitHub：https://github.com/Andrew-Qibin/SPNet
 1"><meta name="keywords" content="博客,Hexo,车辆工程,Linux"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">zilch个人博客</a></h3><div class="description"><p>言念君子，温其如玉</p></div></div></div><ul class="social-links"><li><a href="https://github.com/hezl1592" target="_blank" rel="noopener"><i class="fa fa-github"></i></a></li><p><a href="https://github.com/hezl1592" target="_blank" rel="noopener"><img src="https://ghchart.rshah.org/hezl1592" width="70%"></a></p></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me" target="_blank" rel="noopener"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole" target="_blank" rel="noopener"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>深度学习 | Strip Pooling</a></h3></div><div class="post-content"><p>论文名称：Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</p>
<p>论文链接：<a href="https://arxiv.org/abs/2003.13328" target="_blank" rel="noopener">https://arxiv.org/abs/2003.13328</a></p>
<p>GitHub：<a href="https://github.com/Andrew-Qibin/SPNet" target="_blank" rel="noopener">https://github.com/Andrew-Qibin/SPNet</a></p>
<h3 id="1-摘要"><a class="markdownIt-Anchor" href="#1-摘要"></a> 1 摘要</h3>
<p>事实证明，空间池可有效捕获用于场景分析等像素级预测任务的远程上下文信息。在本文中，除了通常具有规则形状N×N的常规空间池化之外，我们还通过引入一种称为条带池化的新池化策略来重新考虑空间池化的公式，该策略考虑了一个长而窄的核，即1×N或N×1。基于条带化池，我们进一步研究空间池化体系结构的设计，方法是：1）引入一个新的条带池化模块，该模块使骨干网络能够有效地对远程依赖性进行建模； 2）展示具有多种空间池化的新型构建块；3）系统地比较建议的条带池和常规空间池技术的性能。两种新颖的基于池的设计都是轻量级的，并且可以在现有场景解析网络中用作有效的即插即用模块。在流行的基准（例如ADE20K和Cityscapes）上进行的大量实验表明，我们的简单方法建立了最新的技术成果。</p>
<h3 id="2-论文内容"><a class="markdownIt-Anchor" href="#2-论文内容"></a> 2 论文内容</h3>
<h4 id="模块效果图"><a class="markdownIt-Anchor" href="#模块效果图"></a> 模块效果图</h4>
<p style="text-align:center">
    <img src="Snipaste_2020-06-23_14-54-03.jpg" width="40%">
    <img src="Snipaste_2020-06-23_14-54-37.jpg" width="40%">
</p>
<h4 id="spmstrip-pooling-module"><a class="markdownIt-Anchor" href="#spmstrip-pooling-module"></a> SPM(Strip Pooling Module)</h4>
<p>SPM由两条路径组成，它们分别侧重于沿着水平和垂直空间两个维度捕获远程上下文。</p>
<p>与全局平均池化相比，条纹池化考虑的是较长但较窄的范围，而不是整个特征图，避免了在相距较远的位置之间建立不必要的连接。与需要大量计算来建立每对位置之间关系的基于注意力的模块（no-local ）相比，SPM是轻量级的，可以很容易地嵌入到任何构建块中，从而提高捕获远程空间依赖关系和利用通道间依赖项的能力。</p>
<p style="text-align:center">
    <img src="Snipaste_2020-06-23_14-57-16.jpg" width="70%">
</p>
<h4 id="mpmmixed-pooling-module"><a class="markdownIt-Anchor" href="#mpmmixed-pooling-module"></a> MPM(mixed pooling module)</h4>
<ul>
<li>如果因为上面的考虑将网络中的所有pooling全部换成strip pooling操作，则必然会影响原来的非长条物体的效果，就得不偿失了。因此，作者将strip pooling和pyramid pooling都加入进来，构造成mixed pooling module</li>
<li>其中，strip pooling用于解决long-range dependencies，而轻量级的pyramid pooling用于解决short-range dependencies</li>
</ul>
<p>作者提出了一种新的附加组件块，称为混合池模块(MPM)，以进一步在高语义级别上建模长期依赖关系。它通过利用具有不同内核形状的池化操作来探测具有复杂场景的图像，从而收集有用的上下文信息。之前的研究结果表明，金字塔池模型(pyramid pooling module, PPM)是增强语义分割网络的有效方法。然而，PPM严重依赖于标准的池化操作(尽管不同的池内核位于不同的金字塔级别)。考虑到标准池化和条纹池化的优点，作者改进了PPM，提出了混合池模块(MPM)，它侧重于通过各种池化操作聚合不同类型的上下文信息，以使特征表示更有辨别力。</p>
<p style="text-align:center">
    <img src="Snipaste_2020-06-23_15-09-18.jpg" width="40%">
</p>
<h3 id="3-代码"><a class="markdownIt-Anchor" href="#3-代码"></a> 3 代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StripPooling</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, pool_size, norm_layer, up_kwargs)</span>:</span></span><br><span class="line">        super(StripPooling, self).__init__()</span><br><span class="line">        self.pool1 = nn.AdaptiveAvgPool2d(pool_size[<span class="number">0</span>])</span><br><span class="line">        self.pool2 = nn.AdaptiveAvgPool2d(pool_size[<span class="number">1</span>])</span><br><span class="line">        self.pool3 = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="literal">None</span>))</span><br><span class="line">        self.pool4 = nn.AdaptiveAvgPool2d((<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        inter_channels = int(in_channels/<span class="number">4</span>)</span><br><span class="line">        self.conv1_1 = nn.Sequential(nn.Conv2d(in_channels, inter_channels, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels), nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.conv1_2 = nn.Sequential(nn.Conv2d(in_channels, inter_channels, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels), nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.conv2_0 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels))</span><br><span class="line">        self.conv2_1 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels))</span><br><span class="line">        self.conv2_2 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels))</span><br><span class="line">        self.conv2_3 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, (<span class="number">1</span>, <span class="number">3</span>), <span class="number">1</span>, (<span class="number">0</span>, <span class="number">1</span>), bias=<span class="literal">False</span>), norm_layer(inter_channels))</span><br><span class="line">        self.conv2_4 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, (<span class="number">3</span>, <span class="number">1</span>), <span class="number">1</span>, (<span class="number">1</span>, <span class="number">0</span>), bias=<span class="literal">False</span>), norm_layer(inter_channels))</span><br><span class="line">        self.conv2_5 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels), nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.conv2_6 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(inter_channels), nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.conv3 = nn.Sequential(nn.Conv2d(inter_channels*<span class="number">2</span>, in_channels, <span class="number">1</span>, bias=<span class="literal">False</span>), norm_layer(in_channels))</span><br><span class="line">        <span class="comment"># bilinear interpolate options</span></span><br><span class="line">        self._up_kwargs = up_kwargs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        _, _, h, w = x.size()</span><br><span class="line">        x1 = self.conv1_1(x)</span><br><span class="line">        x2 = self.conv1_2(x)</span><br><span class="line">        x2_1 = self.conv2_0(x1)</span><br><span class="line">        x2_2 = F.interpolate(self.conv2_1(self.pool1(x1)), (h, w), **self._up_kwargs)</span><br><span class="line">        x2_3 = F.interpolate(self.conv2_2(self.pool2(x1)), (h, w), **self._up_kwargs)</span><br><span class="line">        x2_4 = F.interpolate(self.conv2_3(self.pool3(x2)), (h, w), **self._up_kwargs)</span><br><span class="line">        x2_5 = F.interpolate(self.conv2_4(self.pool4(x2)), (h, w), **self._up_kwargs)</span><br><span class="line">        x1 = self.conv2_5(F.relu_(x2_1 + x2_2 + x2_3))</span><br><span class="line">        x2 = self.conv2_6(F.relu_(x2_5 + x2_4))</span><br><span class="line">        out = self.conv3(torch.cat([x1, x2], dim=<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> F.relu_(x + out)</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h3>
<blockquote>
<p><a href="https://www.cnblogs.com/xiangs/p/12747816.html" target="_blank" rel="noopener">论文笔记-Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/122571198" target="_blank" rel="noopener">CVPR2020-语义分割：Strip Pooling（条纹池化）</a></p>
</blockquote>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2020-06-23</span><i class="fa fa-tag"></i><a class="tag" href="/tags/深度学习/" title="深度学习">深度学习 </a><a class="tag" href="/tags/Pytorch/" title="Pytorch">Pytorch </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2020/06/23/深度学习_Strip-Pooling/,zilch个人博客,深度学习 | Strip Pooling,;" target="_blank" rel="noopener"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2020/06/27/%E5%BC%80%E5%8F%91_Python_Matlab_TCP%E9%80%9A%E4%BF%A1/" title="开发 | Python与Matlab间建立TCP通信">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2020/06/03/%E5%BC%80%E5%8F%91_Docker/" title="开发 | Docker">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>