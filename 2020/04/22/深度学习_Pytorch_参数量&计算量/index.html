<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="zilch"><title>深度学习 | 卷积操作参数量和计算量 · zilch个人博客</title><meta name="description" content="卷积神经网络在图像处理中的地位已然毋庸置疑。卷积运算具备强大的特征提取能力、相比全连接又消耗更少的参数，应用在图像这样的二维结构数据中有着先天优势。
1. 常规卷积运算假设输入层为一个大小为64×64像素、三通道彩色图片。经过一个包含4个Filter的卷积层，最终输出4个Feature Map，且尺"><meta name="keywords" content="博客,Hexo,车辆工程,Linux"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">zilch个人博客</a></h3><div class="description"><p>言念君子，温其如玉</p></div></div></div><ul class="social-links"><li><a href="https://github.com/hezl1592" target="_blank" rel="noopener"><i class="fa fa-github"></i></a></li><p><a href="https://github.com/hezl1592" target="_blank" rel="noopener"><img src="https://ghchart.rshah.org/hezl1592" width="70%"></a></p></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me" target="_blank" rel="noopener"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole" target="_blank" rel="noopener"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>深度学习 | 卷积操作参数量和计算量</a></h3></div><div class="post-content"><p>卷积神经网络在图像处理中的地位已然毋庸置疑。卷积运算具备强大的特征提取能力、相比全连接又消耗更少的参数，应用在图像这样的二维结构数据中有着先天优势。</p>
<h3 id="1-常规卷积运算"><a href="#1-常规卷积运算" class="headerlink" title="1. 常规卷积运算"></a>1. 常规卷积运算</h3><p>假设输入层为一个大小为64×64像素、三通道彩色图片。经过一个包含4个Filter的卷积层，最终输出4个Feature Map，且尺寸与输入层相同。整个过程可以用下图来概括。</p>
<p>input：$(N, C_{\text{in}}, H, W)$，output：$(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})$</p>
<script type="math/tex; mode=display">
\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
        \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)</script><p style="text-align:center">
    <img src="conv_1.gif" width="22%">
    <img src="conv.jpg" width="50%">
</p>



<ul>
<li><p><strong>图片卷积输出大小计算公式</strong></p>
<p>输入图像大小$(C_{in}, W_{in},H_{in})$，卷积核Filter大小：$(F,F)$，步长：$S$，填充$padding$：$P$：</p>
<script type="math/tex; mode=display">
H_{out} = \left\lfloor\frac{H_{in}  + 2 \times P - F}{\text{S}} + 1\right\rfloor</script><script type="math/tex; mode=display">
W_{out} = \left\lfloor\frac{W_{in}  + 2 \times P - F}{\text{S}} + 1\right\rfloor</script></li>
<li><p><strong>参数量</strong></p>
<p>假设一个卷积核的大小为$(K,K)$，输入的特征图为$(C_{in}, H, W)$，输入为$(C_{out}, H_{out},W_{out})$，不考虑偏置，不补0的卷积。参数量为（即卷积核个数*卷积核参数+偏置数）：</p>
<script type="math/tex; mode=display">
C_{in} \times K\times K\times C_{out}</script></li>
<li><p><strong>计算量</strong></p>
<p>MAC(Multiply Accumulate)，需要考虑输出map的大小，1个MAC算两次操作</p>
<script type="math/tex; mode=display">
K\times K \times W_{out} \times H_{out}\times C_{in}\times C_{out}</script></li>
<li><p><strong>示例</strong></p>
<ul>
<li>输入维度:（6, 64, 64），卷积核:（3, 3），padding=1，stride=1；</li>
<li>输出shape：(3, 64, 64)；</li>
<li>参数：$params = 6\times 3\times 3\times 3 = 162$</li>
<li>计算量：$flops=3\times 3\times 64\times 64\times 6\times 3=663552$</li>
</ul>
<p>用Pytorch展示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchsummary</span><br><span class="line"><span class="keyword">import</span> thop</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_ch, out_ch, group=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch,</span><br><span class="line">                               groups=group, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>,</span><br><span class="line">                               padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = BaseNet(<span class="number">6</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">input_tensor = torch.rand(<span class="number">1</span>,<span class="number">6</span>,<span class="number">64</span>,<span class="number">64</span>)</span><br><span class="line">input_size = tuple(input_tensor.shape[<span class="number">1</span>:])</span><br><span class="line">torchsummary.summary(model, input_size=input_size, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"thop:"</span>)</span><br><span class="line">flops, params = thop.profile(model=model, inputs=(input_tensor,))</span><br><span class="line">print(flops, params)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param <span class="comment">#</span></span><br><span class="line">================================================================</span><br><span class="line">            Conv2d<span class="number">-1</span>             [<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>]             <span class="number">162</span></span><br><span class="line">================================================================</span><br><span class="line">Total params: <span class="number">162</span></span><br><span class="line">Trainable params: <span class="number">162</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): <span class="number">0.09</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.09</span></span><br><span class="line">Params size (MB): <span class="number">0.00</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">0.19</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">thop:</span><br><span class="line">[INFO] Register count_convNd() <span class="keyword">for</span> &lt;<span class="class"><span class="keyword">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">conv</span>.<span class="title">Conv2d</span>'&gt;.</span></span><br><span class="line"><span class="class">[<span class="title">WARN</span>] <span class="title">Cannot</span> <span class="title">find</span> <span class="title">rule</span> <span class="title">for</span> &lt;<span class="title">class</span> '<span class="title">__main__</span>.<span class="title">BaseNet</span>'&gt;. <span class="title">Treat</span> <span class="title">it</span> <span class="title">as</span> <span class="title">zero</span> <span class="title">Macs</span> <span class="title">and</span> <span class="title">zero</span> <span class="title">Params</span>.</span></span><br><span class="line"><span class="class">663552.0 162.0</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-分组卷积"><a href="#2-分组卷积" class="headerlink" title="2. 分组卷积"></a>2. 分组卷积</h3><p><strong>分组卷积(Group Convolution)</strong>：常规卷积的计算结果中，特征图的每个通道和输入特征图的<strong>所有通道</strong>都有关。下方左图是普通卷积的示意图，下放右图是分组卷积的示意图，差别就非常明显了。分组卷积的输出特征图的每个通道，只和输入特征图的一部分通道有关，而这部分通道，就是一个分组(Group)。</p>
<p>依旧假设输入特征图的尺寸为$C_{in} \times H \times W$，分为3组进行分组卷积，那么，对于每一组，输出特征图的通道数都是$C_{out}/3$，卷积核大小变为$C_{in} \times K \times K$，最后只需要将各个分组的计算结果按照通道进行连接(Cat)即可。</p>
<p style="text-align:center;margin:0 auto;">
    <img src="conv_group_1.png" width="25%">
    <img src="conv_group_2.png" width="25%">
</p>

<p>分组卷积可以很大程度上减少卷积所需的参数量，相同的输入输出特征图，分组卷积所需的参数量为：</p>
<script type="math/tex; mode=display">
\frac{C_{in} \times K\times K\times C_{out}}{3}</script><p>即，分组卷积可将参数量减少为原来的$1/G$，$G$为分组数量。</p>
<p style="text-align:center;margin:0 auto;">
    <img src="conv_group_3.png" width="30%">
    <img src="conv_group_4.png" width="30%">
</p>

<p>分组卷积最早出现在AlexNet中，如下图所示。在CNN发展初期，GPU资源不足以满足训练任务的要求，因此，Hinton采用了多GPU训练的策略，每个GPU完成一部分卷积，最后把多个GPU的卷积结果进行融合。</p>
<ul>
<li><p><strong>代码实例</strong></p>
<ul>
<li>输入维度:（6, 64, 64），卷积核:（3, 3），padding=1，stride=1, group=3;</li>
<li>输出shape：(3, 64, 64)；</li>
<li>参数：$params = (6\times 3\times 3\times 3) /3= 54$</li>
<li>计算量：$flops=(3\times 3\times 64\times 64\times 6\times 3)/3=221184$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_ch, out_ch, group=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch,</span><br><span class="line">                               groups=group, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>,</span><br><span class="line">                               padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">model = BaseNet(<span class="number">6</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">input_tensor = torch.rand(<span class="number">1</span>,<span class="number">6</span>,<span class="number">64</span>,<span class="number">64</span>)</span><br><span class="line">input_size = tuple(input_tensor.shape[<span class="number">1</span>:])</span><br><span class="line">torchsummary.summary(model, input_size=input_size, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"thop:"</span>)</span><br><span class="line">flops, params = thop.profile(model=model, inputs=(input_tensor,))</span><br><span class="line">print(flops, params)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param #</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">            Conv2d-1             [1, 3, 64, 64]              54</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 54</span><br><span class="line">Trainable params: 54</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.09</span><br><span class="line">Forward&#x2F;backward pass size (MB): 0.09</span><br><span class="line">Params size (MB): 0.00</span><br><span class="line">Estimated Total Size (MB): 0.19</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">thop:</span><br><span class="line">[INFO] Register count_convNd() for &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;.</span><br><span class="line">[WARN] Cannot find rule for &lt;class &#39;__main__.BaseNet&#39;&gt;. Treat it as zero Macs and zero Params.</span><br><span class="line">221184.0 54.0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-深度可分离卷积"><a href="#3-深度可分离卷积" class="headerlink" title="3. 深度可分离卷积"></a>3. 深度可分离卷积</h3><p><strong>深度可分离卷积(DepthwiseSeparable Convolution)</strong>，在Google的<code>Xception</code>以及<code>MobileNet</code>论文中均有描述。它的核心思想是将一个完整的卷积运算分解为两步进行，分别为<code>Depthwise Convolution</code>与<code>Pointwise Convolution</code>。</p>
<p style="text-align:center;margin:0 auto;">
    <img src="conv_dw_sp_1.png" width="40%">
    <img src="conv_dw_sp.png" width="40%">
</p>

<ul>
<li><p><strong>Depthwise Convolution</strong></p>
<p>当分组卷积（Group Convolution）的group等于输入map维度时，分组卷积就变成了depthwise卷积：</p>
<p style="text-align:center;margin:0 auto;">
    <img src="conv_depthwise.png" width="50%">
</p>
</li>
<li><p><strong>Pointwise Convolution</strong></p>
<p>Pointwise Convolution的运算与<strong>常规卷积运算</strong>非常相似，它的卷积核的尺寸为<strong>1×1×M</strong>，M为上一层的通道数。所以这里的卷积运算会将上一步的map在深度方向上进行加权组合，生成新的Feature map。有几个卷积核就有几个输出Feature map。如下图所示：</p>
<p style="text-align:center;margin:0 auto;">
    <img src="conv_depthwise_1.png" width="50%">
</p>
</li>
<li><p><strong>代码实例</strong></p>
<ul>
<li>输入维度:（6, 64, 64），卷积核:（3, 3），padding=1，stride=1, group=3;</li>
<li>输出shape：(3, 64, 64)；</li>
<li>参数：$params = (6\times 3\times 3)+(6\times3)= 72$</li>
<li><p>计算量：$flops=294912$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseNet_DWCONV_sp</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_ch, out_ch, group)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="comment"># depthwise</span></span><br><span class="line">    self.dwconv = nn.Conv2d(in_channels=in_ch, out_channels=in_ch,</span><br><span class="line">                                groups=in_ch, kernel_size=<span class="number">3</span>,</span><br><span class="line">                                stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># pointwise</span></span><br><span class="line">    self.poconv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch,</span><br><span class="line">                                kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.dwconv(x)</span><br><span class="line">        x = self.poconv(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = BaseNet_DWCONV_sp(<span class="number">6</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">input_tensor = torch.rand(<span class="number">1</span>,<span class="number">6</span>,<span class="number">64</span>,<span class="number">64</span>)</span><br><span class="line">input_size = tuple(input_tensor.shape[<span class="number">1</span>:])</span><br><span class="line">torchsummary.summary(model, input_size=input_size, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"thop:"</span>)</span><br><span class="line">flops, params = thop.profile(model=model, inputs=(input_tensor,))</span><br><span class="line">print(flops, params)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param <span class="comment">#</span></span><br><span class="line">================================================================</span><br><span class="line">            Conv2d<span class="number">-1</span>             [<span class="number">1</span>, <span class="number">6</span>, <span class="number">64</span>, <span class="number">64</span>]              <span class="number">54</span></span><br><span class="line">            Conv2d<span class="number">-2</span>             [<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>]              <span class="number">18</span></span><br><span class="line">================================================================</span><br><span class="line">Total params: <span class="number">72</span></span><br><span class="line">Trainable params: <span class="number">72</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): <span class="number">0.09</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.28</span></span><br><span class="line">Params size (MB): <span class="number">0.00</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">0.38</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">thop:</span><br><span class="line">[INFO] Register count_convNd() <span class="keyword">for</span> &lt;<span class="class"><span class="keyword">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">conv</span>.<span class="title">Conv2d</span>'&gt;.</span></span><br><span class="line"><span class="class">[<span class="title">WARN</span>] <span class="title">Cannot</span> <span class="title">find</span> <span class="title">rule</span> <span class="title">for</span> &lt;<span class="title">class</span> '<span class="title">__main__</span>.<span class="title">BaseNet_DWCONV_sp</span>'&gt;. <span class="title">Treat</span> <span class="title">it</span> <span class="title">as</span> <span class="title">zero</span> <span class="title">Macs</span> <span class="title">and</span> <span class="title">zero</span> <span class="title">Params</span>.</span></span><br><span class="line"><span class="class">294912.0 72.0</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="4-空洞卷积"><a href="#4-空洞卷积" class="headerlink" title="4. 空洞卷积"></a>4. 空洞卷积</h3><p>这部分待完善…</p>
<p><strong>空洞卷积(atrous convolutions)</strong>又名扩张卷积（dilated convolutions），向卷积层引入了一个称为 “<strong>扩张率(dilation rate)</strong>”的新参数，该参数定义了卷积核处理数据时各值的间距。</p>
<p><strong>空洞卷积(Dilated/Atrous Convolution</strong>)，广泛应用于语义分割与目标检测等任务中，语义分割中经典的<strong>deeplab系列与DUC</strong>对空洞卷积进行了深入的思考。目标检测中<strong>SSD与RFBNet</strong>，同样使用了空洞卷积。</p>
<p style="text-align:center">
    <img src="conv_atrous.gif" width="30%">
</p>

<p>在相同的计算条件下，空洞卷积提供了更大的感受野。空洞卷积经常用在实时<strong>图像分割</strong>中。当网络层需要较大的感受野，但计算资源有限而无法提高卷积核数量或大小时，可以考虑空洞卷积。</p>
<ul>
<li><strong>空洞卷积的作用</strong><ul>
<li><strong>扩大感受野</strong>：在deep net中为了增加感受野且降低计算量，总要进行降采样(pooling或s2/conv)，这样虽然可以增加感受野，但空间分辨率降低了。为了能不丢失分辨率，且仍然扩大感受野，可以使用空洞卷积。这在检测，分割任务中十分有用。一方面感受野大了可以检测分割大目标，另一方面分辨率高了可以精确定位目标。</li>
<li><strong>捕获多尺度上下文信息：</strong>空洞卷积有一个参数可以设置dilation rate，具体含义就是在卷积核中填充dilation rate-1个0，因此，当设置不同dilation rate时，感受野就会不一样，也即获取了多尺度信息。<strong>多尺度信息在视觉任务中相当重要啊。</strong></li>
</ul>
</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a href="https://blog.csdn.net/tintinetmilou/article/details/81607721" target="_blank" rel="noopener">Depthwise卷积与Pointwise卷积</a></p>
<p><a href="https://www.cnblogs.com/shine-lee/p/10243114.html" target="_blank" rel="noopener">Group Convolution分组卷积，以及Depthwise Convolution和Global Depthwise Convolution</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1453992" target="_blank" rel="noopener">卷积网络基础知识—-Depthwise Convolution &amp;&amp; Pointwise Convolution &amp;&amp; Separable Convolution</a></p>
</blockquote>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2020-04-22</span><i class="fa fa-tag"></i><a class="tag" href="/tags/深度学习/" title="深度学习">深度学习 </a><a class="tag" href="/tags/Pytorch/" title="Pytorch">Pytorch </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2020/04/22/深度学习_Pytorch_参数量&amp;计算量/,zilch个人博客,深度学习 | 卷积操作参数量和计算量,;" target="_blank" rel="noopener"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2020/04/26/C++_const%E9%99%90%E5%AE%9A%E7%AC%A6/" title="C++ | const限定符">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2020/04/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" title="深度学习 | 分类模型评价指标">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>